\documentclass[output=paper]{langsci/langscibook} 
\author{Klaus Ziegler\affiliation{AIIC Technical Committee}\lastand Sebastiano Gigliobianco\affiliation{SDI München}}
\title{Presence? Remote? Remotely present! New technological approaches to remote simultaneous conference interpreting}
\shorttitlerunninghead{Presence? Remote? Remotely present!}
% \chapterDOI{} %will be filled in at production

%\epigram{Change epigram in chapters/03.tex or remove it there }
\abstract{Since  the 1970’s there have been several approaches to test and implement remote interpreting  as complementary interpreting modality in addition to the traditional and proven interpretation on site. The reasons for experimenting with remote interpretation in conference settings are manifold and can generally be classified by economic aspects, availability issues or organizational matters. In this paper we discuss the preliminary results of a pilot study aimed at exploring how the limitations of remote interpreting described by the literature could be overcome using new technological advances in Information and Communication Technology. We discuss challenges and technological solutions for remote simultaneous conference interpreting from an interdisciplinary perspective and sketch out what future workspace for conference interpreters might look like.}
\maketitle

\begin{document}
% \todo[inline]{Please check order of footnotes and punctuation throughout this chapter}
\section{Introduction}
\largerpage
\label{sec:ziegler:01}
Since the 1970’s there have been several approaches to test and implement remote interpreting as a complementary interpreting modality in addition to the traditional and proven interpretation on site, with all the parties involved (speakers, audience and interpreters) being present in the same room, thus communicating in a more or less face-to-face scenario. The reasons for experimenting with remote interpretation in conference settings are manifold and can generally be classified by economic aspects (e.g. reduced travel costs for interpreters and/or speakers and/or audience), availability issues (e.g. no local interpreters available for a specific language combination) or organizational matters (e.g. an interpreter team can be hired within a shorter period of time, room design does not allow for interpreting booths or booths are simply not wanted to be seen in the room). 

Despite the, to a certain extent, encouraging results of studies, tests and experiments carried out throughout history at \textsc{unesco} 1976\footnote{\citealt{Kurz2000}}, the United Nations (1978\footnote{\citealt{Chernov2004}}, 1982\footnote{\citet{UNESCO1987}}, 2001\footnote{\citealt{Mouzourakis2006}}), the European Union (1992\footnote{\citealt{Kurz2000}}, 2001\footnote{\citealt{Europarl2001}}, 2005\footnote{\citealt{Roziner2010}}) using different technologies for the transmission of audio and video signals from and to interpreters, there have always been two main factors preventing the large scale implementation of remote conference interpretation: technological limitations (due to insufficient availability of bandwidth for the synchronized transmission of sound and image with the necessary quality when transmitting via Internet or telecommunication network, or very high costs when using satellite communication, either exclusively or in combination with terrestrial transmission technologies) and the more or less general refusal of the use of so called “new technologies” by conference interpreters. Apart from measurable physiological factors like fatigue and stress, leading to symptoms such as headaches and concentration problems, interpreters used to complain about the unease they were feeling because of not “being there” \citep{Mouzourakis2006} 
% \todo{add page}
and not having the possibility to get the right feeling for the situation, attributing these psychological symptoms mainly to the limited view of the speaker and the audience as well as not having the possibility to interact directly with the other participants of the event.

In the last few years, general conditions for conference interpreting have been changing constantly due to globalization and altered market needs, on the one hand, but also due to digitalization and extremely fast developing information and communication technologies. The availability of hardware and software for dynamic monitoring and controlling of important parameters like lip synchronization, latency, video resolution and frequency response as well as network infrastructures that allow for simultaneous transmission of high definition video and high quality audio signals via Internet, combined with latest video, virtual reality and augmented reality technologies might offer possibilities to overcome existing technological, physiological and psychological problems. 

\section{Interdisciplinary and terminological challenges}

\label{sec:ziegler:02}
One major challenge when discussing “remote interpreting” as a method for the delivery of interpreting services resides in the fact that there are a lot of different concepts being used in practice by the different stakeholders when referring to this method. While this linguistic phenomenon can be explained, to a certain extent, by the fact that interpreters, in general, simply are not experts in the technical field and therefore use technical concepts without knowing exactly what the technical background for certain scenarios is and what the implications of a certain technical setup exactly are, we can observe that there is still no harmonized terminology being used even by technical experts and researchers. 

Technically speaking, a video conference and video conferencing can be defined as 

\begin{quote}
	a live, visual connection between two or more people residing in separate locations for the purpose of communication. At its simplest, video conferencing provides transmission of static images and text between two locations. At its most sophisticated, it provides transmission of full-motion video images and high-quality audio between multiple locations \citep{TechTarget2017}.
\end{quote}

This definition shows that the same concept is being used for a huge variety of different technical setups.

When it comes to including interpreters in communication to facilitate the necessary translation between the languages that are being spoken by the participants in a communicative event, things become even more diffuse. The term ‘remote interpreting’ as one of the most widely used concepts, covers a whole range of technologically very different setups. These setups range from a traditional presence-based scenario where interpreters, main speakers and the audience are concentrated at one event location, and one or several secondary speakers are connected from a distance for a limited sequence of time, to a situation where none of the actors within the triad speaker-listener-interpreter is at the same location as the others. 

Braun takes up this terminological challenge saying that 

\begin{quote}
Two main uses of telephone and videoconference communication can be distinguished in connection with interpreting. One of these, {remote interpreting (\textsc{ri})}, refers to the use of communication technologies to gain access to an interpreter in another room, building, town, city or country. In this setting, a telephone line or videoconference link is used to connect the interpreter to the primary participants, who are together at one site \citep[1]{Braun2015},
\end{quote}

thus excluding a setup where the participants are located at different locations. For this case, she introduces the concept of “{teleconference interpreting} to cover both telephone and videoconference communication” \citep[2]{Braun2015}. Further on, she introduces as a separate term

\begin{quote}
	{teleconference interpreting} to cover both telephone and videoconference communication (ibid.)
\end{quote}

For disambiguity purposes, she then introduces the terms “{telephone-based interpreting}” and “{videoconference-based interpreting}” (ibid.), but adds that there are a lot of additional concepts being used in practice.

For the purposes of this article, we broaden up the perspective and adhere to the definition given in the recently published \citet{ISO20108}, introducing the term of ‘distance interpreting’ (with ‘remote interpreting’ as admitted term), giving the definition of ‘interpreting of a speaker in a different location from that of the interpreter, enabled by information and communications technology (\textsc{ict})’. 

Analyzing technological, communicative, cognitive, physiological and psychological aspects it becomes clear very soon that every single dislocation of one of the emitting or receiving elements (speaker, listener or interpreter) to a different location (thus becoming a distant location) has a considerable impact on the technological setup and the components and transmission channels needed to enable communication between the different parties involved. 

Furthermore, communicative aspects like verbal and non-verbal communication are altered by the rearrangement of the setting, as elements like gestures, facial expressions etc. cannot be perceived directly anymore, and have to be captured, transmitted and reproduced again at the distant site in order to be made available.

As far as cognition is affected, the cognitive load generated by additional or, at least, altered receptive and productive tasks that interpreters will have to manage while performing, related to the sub-processes of listening to a source text, processing its content and re-producing that content in the target language, is also being influenced significantly by every alteration of the setting \citep{Moser-Mercer2005}. Research has revealed that cognition is intimately linked to physiological processes that take place in the human body, especially the brain as the controlling unit, and that a variation of acoustic and visual input to interpreters has an impact on vital functional systems like the respiratory system, metabolism and others, leading to stress, earlier fatigue and other phenomena \citep{Moser-Mercer2003}.

Last, but not least, there is also a wide range of psychological factors that have to be considered when approaching ``distance interpreting'' from an interdisciplinary point of view. In an ideal setting, communication taking place with all participants being at the same location, in the same room and with no obstacles impeding direct mutual perception, allows the participants in the communicative event to make use of at least four out of the five basic human senses: touch, smell, see, hear. Whereas most of the related parameters, such as neuronal stimulation for haptic feedback, composition of ambient air for smelling, audio frequencies for hearing and light waves for vision can easily be measured, quantified and evaluated, other phenomena such as energy fields (sometimes referred to as mental, astral/emotional and etheric/physical bodies) that affect the balance of both the physical body and the non-physical mind, are much more difficult to capture and evaluate, although they might have an influence on human interaction and, by that, on communication.

Whereas many interesting aspects related to distance interpreting have been addressed based on other interpreting specializations, such as legal interpreting (see \textsc{avidicus} projects 1--3), there have not yet been similar large-scale projects directly or indirectly related to distance simultaneous conference interpreting. However, several aspects have been studied on a smaller scale, such as stress and performance in remote interpreting \citep{Moser-Mercer2003,Roziner2010}, perception of remote interpreting by interpreters \citep{Mouzourakis2006} or visual input \citep{Rennert2008,Luisetto2016}.

\section{Solutions in the past}
\label{sec:ziegler:03}
\subsection{Tests and experiments \textsc{unesco}, \textsc{un}}
\label{sub:ziegler:3.1}
Since the seventies, due to a quick development in telecommunication technology, big international institutions such as the United Nations or the European Union have begun testing new interpreting solutions to reduce the cost of conferences \citep[26]{UNESCO1987}.

One of the first experiments with remote interpreting took place in 1976 when the \textsc{unesco} organized its general assembly in Nairobi. The interpreters, however, were asked to work from Paris, which was connected to the capital city of Kenia thorough a satellite connection which provided an audio and video connection quality equal to that of a standard \textsc{tv} broadcast \citep[30]{Mouzourakis1996}. The interpreters were not satisfied with their performance and stated that they were more tired and stressed than usual \citep[294]{Kurz2000}.

A second experiment with remote interpreting was organized in 1978 by the United Nations. The conference was held in Buenos Aires and there were interpreters working both in Buenos Aires and in New York, the latter received audio and video signals through a satellite connection. The results showed that it was possible for the interpreters working in New York to achieve a high quality interpretation, \citep[26]{UNESCO1987} although the interpreters working in Buenos Aires were able to deliver a better performance due to their more intensive preparation and knowledge about the conference \citep[82--90]{Chernov2004}. 

Another experiment with satellite connection took place in Vienna in 1982 during the United Nation conference on the Exploration and Peaceful Use of Outer Space. At this conference, the interpreters worked in Vienna as well, but not in the same building \citep[10]{Andres2009}. The communication was a success, but the interpreters complained of increased stress \citep[26]{UNESCO1987}.

Although these experiments with satellite connection between the 70’s and the 80’s demonstrated that remote interpreting was possible, the huge costs and the increased level of stress led to the conclusion that this technology was too expensive and immature to be used yet (ibid. 26).

Thanks to the ongoing advancement of \textsc{ict} and the growth of the European Union, new possibilities for remote interpreting arose. From the beginning of the nineties onward the European Union was the main driving force behind this development with the aim to create a central hub where the interpreters could work \citep[3]{Braun2011b}.

One of the first positive results was achieved in 1999 in Vienna using \textsc{isdn} technology during a \textsc{un} Inter-Agency Meeting on Language Arrangements, Documentations and Publications which was held in Geneva and interpreted from Vienna. During this experiment, the transmitted audio signals were based for the first time on a frequency going up to 7\,kHz. The conference hall in Geneva was recorded by three cameras and the pictures were projected in Vienna using a projection screen with a transmission rate of 384\,kbps \citep[63]{Mouzourakis2006}. The audience was satisfied with the performance of the interpreters and for the first time the interpreters were pleased with the quality of the audio transmission, although they criticized the video quality \citep[11]{Andres2009}. Two months later a second experiment was organized together with the International Telecommunication Union (\textsc{itu}) and the École de Traduction et d’Interprétation (\textsc{eti}). For this experiment two French booths were installed: one in the conference hall and a second one in a remote location. In this case the audio signal was encoded in \textsc{mp3} format and the video signal was transmitted with a rate of 382\,kbps \citep[63]{Mouzourakis2006}. The audience alternately received the signal from the local and remote booth and was happy with the results. The interpreters, on the other hand, perceived the physical distance from the conference hall and had a feeling of losing control over the situation. Interestingly, saliva samples were taken from both booths before and after the conference, but contrary to what the interpreters stated, no relevant difference was noted in stress hormones \citep{Moser-Mercer2003}.

A new experiment was organized in 2001 in New York by the United Nations in which both \textsc{isdn} and satellite connection were tested. The conference was recorded using three cameras and a 42-inch plus a 25-inch plasma screens were installed in front of the booths. With this experiment, the \textsc{un} laid down the following minimum requirements for remote interpreting:

\begin{quote}
14\,kHz sound (requiring 128\,kbps) for sending floor sound to the booths (14\,kHz) and 10\,kHz sound (at 64\,kbps) for sending interpretation back to the floor (10\,kHz); 512\,kbps for the image of the speaker plus 384\,kbps for the floor/podium image. \citep[63]{Mouzourakis2006}
\end{quote}

Two new studies took place in 2001 and 2005 at the European Parliament to test a connection through optic fibre (ibid. 64). The results of the first experiment showed that the interpreters were satisfied with the audio and video quality. However, they criticised the selection of pictures and the fact that they did not have a comprehensive view of the conference room \citep[19--21]{Europarl2001}. Moreover, they stated that they felt uncomfortable and that the remote interpretation setting is overall more tiring (ibid. 22--23). The second experiment, which lasted five weeks, brought similar results: the interpreters were pleased with the audio and video quality although a complete view of the audience was lacking. Moreover, they felt alienated and isolated from the conference and the screens caused eye-burning, headaches, loss in concentration and higher tension and fatigue. They also stated that they felt their performance was of inferior quality while working remotely. Medical examinations, however, found no evidence of increased stress and a performance evaluation confirmed that the interpreters’ performance working remotely was slightly inferior, but not enough to reach statistical relevance \citep[225--243]{Roziner2010}.

\section{Solutions at present}
\label{sec:ziegler:04}
\subsection{\textsc{lan} based solutions} 
\label{sub:ziegler:4.1}
An example of a remote interpreting solution which is based on a local network is currently being used by the Directorate General for Interpretation of the European Commission (\textsc{dg scic}). In this setting, interpreters work from a conventional permanent booth located in another room at the same location, although occasionally mobile booths were also used, in front of which 4 high resolution screens are placed. Through the screens, interpreters receive the following images:

\begin{itemize}
\item On a 50” full \textsc{hd} screen with split view, an overview of the entire meeting table from two different angles is shown. Thanks to the big screen and the high resolution, the interpreters are able to see all the participants’ faces.
\item An image of the active speaker is transmitted on two 22” full \textsc{hd} screens which are places laterally to the 50” screen
\item A static shot of the presidency is displayed on a third 22” Full \textsc{hd} screen which is placed on top of the 50” screen.
\end{itemize}

In order to transmit the images from the meeting room to the interpreting room, optic fibre cables are used \citep{Technical2016}. 

\subsection{Solutions with external data transmission} 
\label{sub:ziegler:4.2}
With the growing demand for a more flexible and less money consuming delivery of interpreting services in a globalized world, several attempts were made in the last decade to overcome restrictions and to make use of technologies allowing to leave the traditional presence-based scenario with a direct wired connection of all components of the conference system (see \sectref{sec:ziegler:03}). For the purposes of this article and from a merely technological point of view, these technologies can be divided into solutions including the transmission of either only audio signals, or the transmission of both audio and video signals to the interpreters. 

\subsubsection{Audio conferencing solutions}
\label{sub:ziegler:4.3}
One approach to overcome existing limitations of bandwidth and thus the impossibility for transmitting sound and image to the interpreters with the required quality (see \sectref{sec:ziegler:03}) consists in reducing the transmitted content exclusively to the audible signals. The most accessible and therefore most frequently used technology for this transmission relies on the use of telephony. In technical terms, a first very rough distinction has to be made between traditional land lines and mobile telephony, as the audible frequencies are mainly being transmitted either via wired connection (land line) or as waves through the air (although mobile telephony also includes sections where the transmission is being carried out by wire, as it is the case in the mobile devices themselves or the re-transmitting stations in between). The use of copper cable and the non-existence of fibre optic connections in certain areas, but also the necessity of handling billions of those connections at a time, still lead to a considerable cutting down of the audio frequencies being transmitted to a maximum of 8\,kHz, even if land lines today are more and more often based on digital VoIP technology\footnote{For a comparison of VoIP coding algorithms, see \citet{Singh2016}}. Whereas for consecutive interpreting the range of up to 8.000\,Hz might be enough (often named ‘wideband audio’) because of the clear separation of the reception (hearing) and producing (talking) processes on the interpreter’s side, simultaneous interpreting with listening and talking at the same time is considerably affected by the loss of frequencies due to the masking effect generated by the interpreter’s own voice, making incoming frequencies on the same level not audible anymore \citep{Jumpelt1984}. As a result, the physical and cognitive effort for hearing will increase and, depending on the frequency of the incoming voice of the speaker and the interpreter’s own voice (note that e.g. female and male voices are located in different frequency ranges), the interpreter’s output quality will necessarily decrease despite all efforts to compensate for the missing input by interpreting strategies like variation of the voice-to-ear-span or additional pausing. It should not be forgotten that the interpreter has no possibility to compensate for the absence of audible input by visual input when using audio-only solutions. Even if these technologies have improved a lot and specially designed audio bridges allow controlling incoming and outgoing signals with a high level of quality of service even in multilingual scenarios, the above described acoustic parameters cannot be neglected.

\subsubsection{Video conferencing solutions}
\label{sub:ziegler:4.4}
As far as solutions able to transmit sound and image at the same time are concerned, one of the most frequently used technology is based on video conferencing solutions. These solutions rely on the principle of separately capturing image and sound at the source with camera and microphone, encoding the data with a certain algorithm, transmitting the data packages using one or more parallel lines and decoding the packages again at the destination, making sound and image audible and visible again. These solutions necessarily depend on the availability of adequate and compatible equipment at all source and end points of the communication and the use of a common standard for encoding and decoding of signals (codec). One of the critical points with these video conferencing solutions in terms of quality simultaneous interpreting is the fact that standard codecs use a compressed file format for transmission of audio signals and compression is carried out either by cutting out certain frequencies, or by other procedures causing similar effects as described before for the audio only solutions\footnote{For more information on techniques for video compression see \citet{Wiegand2003}.}.

\section{Technical requirements for remote interpreting}
\label{sec:ziegler:05}
As described above, remote interpreting is a specific method of (conference) interpreting and covers a variety of scenarios of interpreting of a speaker at a different location from that of the interpreter, enabled by information and communication technology. The main aspect in these scenarios is that the interpreter is not physically present in the same room as all the other actors in the communicative event, thus not having a direct view of either the conference room and/or the speaker and/or the audience. To enable interpreters to do their job and deliver a quality service, some technical requirements need to be fulfilled. As we have seen before, different experiments have been carried out in order to identify the minimum technical requirements which are to be observed to assure performance quality.

One of the first attempts to define minimal requirements for remote interpreting was the \textit{Code for the use of new technologies in conference interpreting} which was published by the International Association of Conference Interpreters (\textsc{aiic}) in 2000 together with other national interpreter’s association, the European Parliament, the European Court of Justice and the joint conference and interpreting service of the European Union and the World Customs Organisation \citep[31]{Korak2010}. Without going too much into detail, \textsc{aiic} states that interpreters’ work conditions in remote settings must comply with the requirements set out in \textsc{iso} standards 2603 and 4043 (1998 editions, withdrawn in 2016 and replaced by a new set of \textsc{iso} standards 2603, 4043, 20108 and 20109) which define the work environment of interpreters in mobile and permanent booths. Moreover, the following requirements are to be fulfilled:

\begin{itemize}
\item All frequencies between 125 and 12500\,Hz are to be transmitted.
\item Interpreters must receive high definition images of the speaker and other participants. 
\item The interpreter shall work no more than two hours per day \citep[2]{AIIC2000}.
\end{itemize}

A more comprehensive study commissioned by the European Commission was conducted in 2010 by the \textit{Fraunhofer Institut} to evaluate the minimal requirements of video and audio quality for simultaneous interpretation\footnote{This study was originally published in 2010 by Sporer, Thomas; Fischer, Jens-Oliver; Liebetrau, Judith; Fröhlich, Daniel; Schneider, Sebastian; Kämpf, Sven under the title “Definition of an Objective evaluation method for assessing the minimal quality of digital video and audio sources required to provide simultaneous interpretation. Final Report. Fraunhofer IDMT.” When this article was drafted, it could be found at \url{http://ec.europa.eu/dgs/scic/docs/working_with_int/inf_tech_group/2010-12/fraunhofer_study_2010_final_report.pdf}}. During this study, conference interpreters were asked to evaluate different audio and video signals to assess the impact of transmission quality on their performance. The result of the study is a guideline which states that:

\begin{itemize}
\item All frequencies between 125 and 12500\,Hz must be transmitted, although frequencies starting at 75\,Hz should also be included in the range
\item Video quality should be at least 1280$\times$720 at 50\,Hz with a ratio of 16:9
\item Audio must be synchronized (lip synchronisation) with the video track with a maximum value of \textminus25\,ms or +95\,ms
\end{itemize}

The work of the \textit{Fraunhofer Institut} was used as a starting point to draft the new \textsc{iso}-Standards 20109 “\textit{Simultaneous interpreting -- Equipment -- Requirements“} and 20108 “\textit{Simultaneous interpreting -- Quality and transmission of sound and image input -- Requirements“}, which not only raised the minimum requirements, but also added new ones concerning sound and image transmission:

\begin{itemize}
\item All frequencies between 125 and 15000\,Hz +/\textminus 3\,dB must be transmitted \citep[3]{ISO20109}.
\item Image quality must be good enough to avoid blurring and freezing of the video.\footnote{The draft of the \textsc{iso}-standard 20108 contained more detailed specifications regarding video and transmission requirements: video quality must be at least 720p at 50\,Hz or 1080p at 25\,Hz and the signal must be compressed using at least H.264 at 1152\,kbps. Moreover, the packet loss value should not exceed 0.2\%, jitter should be lower than 15\,ms and the latency (roundtrip) in the system shall not exceed 200\,ms.}
\item Audio must be synchronised with the images with a maximum delay of 45\,ms or advance of 125\,ms.
\item Latency (from the source to the interpreters) must be lower than 500\,ms \citep[7--8]{ISO20108}.
\end{itemize}

\section{Future workspace}
\label{sec:ziegler:06}
Based on the technical parameters exposed in \sectref{sec:ziegler:05}, the authors started an experimental research project with the objective of modelling a future workspace for conference interpreters while performing remotely in simultaneous mode. For these purposes, the framework that was chosen for the experimental study was based on a standard working environment for conference interpreters, including, amongst others, a soundproof simultaneous interpreting booth and a hardware interpreter’s console as audio/video interface. Apart of these technical aspects, the experimental setting was also characterized by some specific markers in terms of interactivity and communication patterns, generally assigned to conference interpreting in literature, such as a mostly monological discourse pattern, interpreting into one language, no possibility for interaction with the speaker during his intervention, a symmetric communicative setting with speakers on the same educational level, the same linguistic code used by both speakers, and no variation of speaker’s registers \citep[582--583]{Angelelli2000}. All tested scenarios in the experiment were designed with a view to possible implementation in conference interpreting “hubs” with a basic technical setup similar to the one that can usually be found at conference venues.

\subsection{The Experiment}
\label{sub:ziegler:6.1}
The experiment took place in Düsseldorf in collaboration with \textsc{pc}s Professional Conference System GmbH. The aim of this experiment was to test three different remote interpreting settings: 

\begin{itemize}
\item using a 65-inch screen with a picture-in-picture function 
\item using a camera remotely controlled by the interpreter, and
\item using a 360-degree camera and Virtual-Reality-Glasses. 
\end{itemize}

Common to all three parts of the experiment was the text which the interpreters had to interpret in simultaneous mode. Two speakers were asked to speak for a total length of circa 10 minutes per scenario. The dialogue was not prepared but rather improvised and the only rule the speakers had was that the first five minutes of the speech had to be informal and the last five of a more technical nature. Since according to the effort model of \citet{Gile2009} interpreters need to distribute their concentration among the different tasks of simultaneous interpreting, the different degree of difficulty of the speeches aimed to test whether interpreters were still able to operate the new device in the booth under different degrees of stress. The interpreters were not informed about the nature of the text they would have to interpret, for the purpose of eliminating preparation as a variable from the equation and to assure that they had to concentrate on the interpreting effort as well. Moreover, since the interpreters had a direct control on the video signals being transmitted, two speakers were intentionally selected in order to force the interpreters to adjust the video settings based on which speaker was talking in order to assure that the new device was actively used during the experiment. The dialogue was held in German and each of the two interpreters was working from his A into his B language. Since the length of each dialogue was only ten minutes and pauses between the scenarios were planned, each interpreter worked alone in the booth while the other was waiting in a separate room, to guarantee equal conditions. Moreover, having each interpreter working alone assured that they were forced to operate the extra technological feature while interpreting, to determine whether and to what extent this would have an impact on their performance. After the experiment, the interpreters were asked to fill out a questionnaire to evaluate the different settings and technological setups. The questionnaire consisted of 28 questions divided into two parts: first a more generic part to create a profile of the subjects with questions about their age, experience, linguistic combination and whether or not they already had experience with remote interpreting, and then a second more specific one, in which, for each scenario, the interpreters were asked to summarize their personal opinion about these new solutions. For example, they were asked whether they could operate the extra devices in the booth, whether they felt they had to put extra effort into it and whether these new solutions were, according to them, better or poorer than a standard video and audio transmission which they could not control. Moreover, for each scenario, they were asked to evaluate the quality of the video transmission on a scale from 1 (poorest) to 5 (best), to share any personal opinion, comment, or criticism and finally to state whether or not they would like to see this solution implemented in the future.

The subjects in this study were both professional conference interpreters holding a degree in conference interpreting. Both started their career more than 16 years ago and stated having worked as conference interpreters between 51 and 100 days per year, and can therefore be qualified as ‘experienced’ professional interpreters. In terms of internal validity of the study it is also important to mention that they stated having had very little or no experience at all with remote interpreting in conference settings. Due to the very small sample of this study, the results of this experiment cannot be generalized. The study aimed primarily at testing the feasibility of these new technologies. To achieve external validity, the study would have to be reproduced on a larger scale and conducted with an appropriate methodological approach.

\subsubsection{Picture-in-Picture} 
\largerpage
The picture-in-picture solution was the first scenario being tested. For this part of the experiment, the speakers were in the conference room, in which two different cameras, each pointed at one speaker, were recording the event. The audio signal was recorded with a wireless microphone and fed together with the video signal to the Extron \textsc{smp 351} recording and streaming processor, which streamed the audio and video tracks over the local network of \textsc{pc}s to the interpreting booth. To guarantee lip synchronisation the audio signal was delayed by 275\,ms before being fed to the Extron. In another room, a 65” monitor was placed 95\,cm from the booth, guaranteeing roughly a distance of 155\,cm between the screen and the eyes of the interpreters. According to \citeauthor{Causo2011}’s guidelines (\citeyear[2]{Causo2011}) the booth was placed in such manner that the windows’ frames of the booth would not obstruct the view of the interpreters. The video signal from the conference room was shown to the interpreters using a picture-in-picture function meaning that both signals were transmitted simultaneously and that one image occupied a larger portion of the screen while the second video feed was displayed in a smaller format in the bottom right corner and the interpreters were able to switch between the two. According to the draft of the \textsc{iso} standard 20108\footnote{When the experiment was conducted, a final version of the \textsc{iso}-Norm 20108 had not been published yet. The draft was therefore used for reference.} (\citeyear[6]{ISO20108}), the video signal was reproduced with a resolution of 1920$\times$1080 pixels at 30 frames per seconds. 

The results showed that both participants reacted positively to this solution and they found it to be better than a static video signal, upon which they have no influence. None of the interpreters noticed any increase in workload due to the more technical nature of the second half of the text and stated that they had no problem in using the new device in the booth to switch between the two pictures. Both interpreters stated that they would like to see this solution implemented in the future.

\subsubsection{Remote controlled camera}

During the second part of the experiment, the speakers were recorded by only one camera placed in the middle of the conference table. From within the booth the interpreters were able to remotely move the camera 270 degrees horizontally and 90 degrees vertically on its axes. The camera was directly connected to the internal local network of \textsc{pc}s and the interpreters were able to move it using a mouse connected to a laptop in the booth. The audio signal was captured separately using a wireless microphone and delayed by 275\,ms before being transferred to the interpreter’s booth using a cable. With a resolution of 1080p by 25 fps, this camera respected the indications of the \textsc{iso} standard 20108 as well. 

The results of the questionnaires showed that this solution was also welcomed by the interpreters and that they quickly got used to the control of the camera via mouse and stated that this could rapidly become an automatism. This solution was also considered to be better than a non-controllable video transmission. None of the interpreters noticed the difference between the first and second part of the dialogue and had no problem with the camera control.

\subsubsection{Virtual reality glasses}
\largerpage
For the last part of the experiment, the interpreters still worked in a normal interpreting booth wearing \textsc{vr}-glasses of the company Elegiant which use a smartphone (in this case an Apple iPhone SE) to reproduce images. The smartphone was directly connected through Wi-Fi to the 360-degree camera used to capture the dialogue between the two speakers. Also in this case, the audio was captured with a wireless microphone and fed to the interpreting booth using a cable after being delayed by 500\,ms. In order to fully exploit the potential of the camera and the \textsc{vr} glasses, the speakers were standing in front of each other in a big hall and asked to move around while talking as well as making use of gestures and mimics.

The opinions of the interpreters on this solution were very different from each other. The first interpreter found the \textsc{vr}-glasses an interesting alternative to a monitor although not very comfortable to wear for a longer period. The subject also stated that, after a short time, one gets used to blindly operating the console in the booth. The second interpreter, on the other hand, was not happy with this solution, finding it tiring for the eyes –- it must be noted that the second interpreter wore glasses and because of the design of the \textsc{vr}-glasses it was not possible to wear both correction and \textsc{vr} glasses -- and complained that it was very difficult if not impossible to operate the console in the booth or use a personal computer for terminology research.

At this point the authors need to clarify that especially this last part of the experiment was of extreme experimental nature and that the results are not particularly conclusive, also due to the small number of participants. The main goal of this experiment, however, was not to test whether the selected model of \textsc{vr} glasses is ready for a practical application in interpreting boots, but rather to make a first test on operability of \textsc{vr} glasses combined with traditional equipment for simultaneous interpreting in soundproof booths. The results of this test shall be used for additional and more elaborate studies in the future.

\subsection{From virtual reality to augmented reality solutions}

The experimental study described in \sectref{sub:ziegler:6.1} suggests that the lack of direct view of the speaker during an event might be compensated for, at least to a certain extent, by the use of technologies that allow the interpreter to control the video input he feels he needs to process non-verbal elements of the content produced by the speaker himself. Nevertheless, a one-dimensional screen reproducing one or several images will always reduce the possibilities of perception of the setting captured with cameras, as there is still a very clear separation of the interpreter in his remote environment and the room where the original event is taking place. The feeling of separation from the action, often referred to as the feeling of not “being there”, might still be big enough as to prevent the interpreter from overcoming this psychologically relevant issue. 

The last step in the experiment described above was to dive into a virtual reality scenario, making the interpreter feel immersed in the situation, e.g. making similar movements with his eyes and/or his head and body as he would be doing if seated in the room with the speaker and the audience, seeking for the necessary visual information to complete the audible content and render the entire intended message to the listeners. Whereas the use of a screen with a double video feed, controlled by the interpreter and reproduced as a picture-in-picture image on a wide screen was accepted by both subjects in the experiment and the additional control task didn’t seem to have any negative effect in terms of cognitive overload, the use of virtual reality glasses clearly showed that the physical separation from the real world and the traditional equipment placed in it (console for controlling audio input and output, and laptop for document and knowledge management) raises several cognitive and ergonomic issues, although the much more dynamic and self-controlled setting was considered positive as such. 

Following this line, the combination of both real and virtual elements in an augmented or mixed reality scenario, where computer-generated images are superimposed on user’s view of the real world, would be the next logical step towards a practical solution for the challenges that remote simultaneous interpreting imposes. \textsc{ar} glasses already being offered on the market like Microsoft’s HoloLens, for example, allow projecting images and possibly other virtual images into the vision field of the interpreter, while he can still see and control the real hardware components he needs for the delivery of the interpreting service. Any software application used for document and knowledge management could be moved from the real world into the virtual world, projecting only the image of the respective interface into the field of vision and allowing him to virtually manipulate the application with his hands. For these purposes, ergonomic aspects such as weight and wearing comfort of the device, cognitive aspects such as real or perceived additional workload and, of course, compliance with the technical parameters as set out for distance interpreting, as well as processing capacity of the processing unit will have to be studied in terms of usability and feasibility.

\subsection{Interpreting hub solution}
\label{sub:ziegler:6.2}
Considering that workspace for conference interpreters working remotely in simultaneous mode should take into account the relevant parameters as stated in existing \textsc{iso} standards 2603/4043, as far as sound insulation, ventilation and ergonomics are concerned, \textsc{iso} 20109, as far as equipment for simultaneous interpreting is concerned, and \textsc{iso} 20108, as far as quality and transmission of sound and image input to interpreters is concerned, workspace solutions for distance interpreting should be designed accordingly, assuring that the most important parameters that allow for quality simultaneous interpreting are met.

Even if for economic reasons a solution with the interpreter working from his home office might seem the most obvious and easiest solution, there are a couple of issues that need to be considered when envisaging such solutions: First of all, in many regions of the world a dedicated internet connection with assured availability of the necessary bandwidth to transmit high definition images together with \textsc{iso} compliant sound to the interpreter, is either non-existent or hardly affordable for a single interpreter. In addition, home office rooms would have to be equipped either with an appropriate interpreting booth or with components assuring compliance with the main parameters of \textsc{iso 2603/4043} in terms of sound insulation, ventilation etc.

A lack of possibilities for dynamic control of the internet connection while interpreting, as well as data protection and confidentiality issues would also have to be resolved if home office workspace were to be used.

Particularly for multilingual events with more than two languages being spoken and interpreted at the same time, a promising approach in terms of Quality of Service both from a technical and an interpreting performance view are solutions with interpreting being performed in specially designed hubs, where interpreters would find all the necessary working conditions to deliver quality interpreting. Traditional \textsc{iso} compliant booths as a minimum standard, or a specifically designed workspace ensuring the basic requirements, equipped with state-of-the-art digital interpreting equipment, dedicated internet connections with permanently available bandwidth according to the number of video and audio feeds needed, controlled ambient conditions with active regulation of air supply and carbon dioxide levels, immersive \textsc{3d} environments with high resolution projection screens and interpreters being able to choose the desired visual input out of several video feeds, \textsc{ar} components, and technical support available on site would set the appropriate technical framework. In addition, offices with access to online and offline information sources for preparation before and during the event, rest rooms for relaxation and lounge areas for the necessary professional and social exchange within the interpreting team, would add other useful elements to overcome the alienation perceived by interpreters working in remote scenarios and environments that have not been developed specifically for this purpose. 

\largerpage
Apart from these more technical aspects, any kind of hub solution would also have to address psychological factors such as measurable or perceived stress. \citet[15]{Moser-Mercer2005} states that “it appears that (…) interpreters seem to be under increased psychological stress when working away from the conference room, mostly because they experience a lack of control of the situation”. Even if there are no studies available yet, that would explain exactly which kind of control interpreters are missing,\footnote{Note that, apart from the interpreter’s console with standard control buttons for the incoming sound, an interpreter in a presence-based conference setting also has only very little control of the actions in the room.} we can suppose that aspects like

\begin{itemize}
\item availability of a technician in case of technical problems,
\item the interaction with team mates working in the same interpreting booth or across booths in multilingual conferences,
\item the (sometimes very limited or even non-existing) possibility of talking to speakers and audience before the conference or during breaks,
\item self-control of the direction of sight, focusing on speaker, audience, presentation or any other visual input available
\end{itemize}

are factors that interpreters feel they need to control.

The design of an interpreting hub as described above could easily cover the first two aspects, as such a hub would necessarily need the presence of a technician onsite in the hub to manage the technical equipment and the whole team (if interpreting takes place from one hub only) or at least the booth mate would be working together at the same place. 
The interaction and communication with speakers and audience would, of course, require a specific solution, but could be handled e.g. considering ‘institutionalized’ briefing and \textsc{q\&a} sessions before, during and after the meeting.

Control of the view on the speaker, audience and additional visual input such as presentations, in presence-based interpreting usually performed by head\linebreak movements and eye focusing, would need further development based on the technologies described in \sectref{sub:ziegler:6.1}. Considering the very fast development of image captioning, transmission and reproduction, it seems only a matter of time until these technologies will be affordable and experience an adaptation to the needs of remote simultaneous conference interpreting. 

\section{Conclusions}
\label{sec:ziegler:07}
In times of growing demand for flexible, accessible and customer oriented digitalized communication services in a globalized world, technological solutions for quality simultaneous interpreting services will have to be developed, taking into account several aspects related to the organization and delivery of those services. Existing standard solutions developed for other purposes, such as video conferencing or web conferencing without interpreting, or solutions for consecutive interpreting in specializations other than conference interpreting, appear not to be sophisticated enough to meet the special requirements that distance interpreting imposes in terms of sound and image input to interpreters in bilingual and multilingual conference settings. Technological enhancements in the field of virtual reality and augmented reality, as well as immersive communication environments may offer the possibility to overcome existing constraints.

One of the major challenges for interpreting studies in the field of distance interpreting will be to find a more interdisciplinary and future oriented approach, building teams of researchers in the technical, medical and psychological field, to name only a few of them, and to combine these different research disciplines in multidisciplinary projects that can actively lead to designing the future work\-space for conference interpreters, in the first place, but for other specialized interpreting services as well. It goes without saying that fellow (conference) interpreters need to be prepared for remote simultaneous interpreting during their training, as this modality is experiencing a growing demand in different interpreting specializations, including tele- and videoconference interpreting \citep{Braun2015}. Apart of the integration of training modules designed specifically for this modality, addressing cognitive, communicative and technical aspects, amongst others, this would also require adequate equipment of training facilities with the appropriate features (audio/video conferencing hard- and software and connectivity, to mention just a few of them).
 
\nocite{ISO2603,ISO4043,AVIDICUS1,AVIDICUS2,AVIDICUS3}
{\sloppy\printbibliography[heading=subbibliography,notkeyword=this]}
\end{document}
